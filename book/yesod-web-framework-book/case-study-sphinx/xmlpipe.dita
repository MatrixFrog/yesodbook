<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="conceptId" outputclass="xmlpipe">
 <title id="x-1">Streaming xmlpipe output</title>
 <conbody id="x-2">
  <p id="x-3">We've saved the best for last. For the majority of Yesod handlers, the recommended approach is
   to load up the database results into memory and then produce the output document based on that.
   It's simpler to work with, but more importantly it's more resilient to exceptions. If there's a
   problem loading the data from the database, the user will get a proper 500 response code.</p>
  <note id="x-4">What do I mean by "proper 500 response code?" If you start streaming a response to a client,
   and encounter an exception halfway through, there's no way to change the status code; the user
   will see a 200 response that simply stops in the middle. Not only can this partial content be
   confusing, but it's an invalid usage of the HTTP spec.</note>
  <p id="x-5">However, generating the xmlpipe output is a perfect example of the alternative. There are
   potentially a huge number of documents (the yesodweb.com code handles tens of thousands of
   these), and documents could easily be several hundred kilobytes. If we take a non-streaming
   approach, this can lead to huge memory usage and slow response times.</p>
  <p id="x-6">So how exactly do we create a streaming response? As we cover in <xref id="x-7" href="../web-application-interface/web-application-interface.dita#web-application-interface" format="dita">the WAI chapter</xref>, we have a ResponseEnumerator constructor that uses a
   stream of blaze-builder <codeph id="x-8">Builder</codeph>s. From the Yesod side, we can avoid the
   normal Yesod response procedure and send a WAI response directly using the <codeph id="x-9">sendWaiResponse</codeph> function. So there are at least two of the pieces of this puzzle.</p>
  <p id="x-10">Now we know we want to create a stream of Builders from some XML content.
   Fortunately, the <apiname id="x-11">xml-enumerator</apiname> package provides this interface
   directly. xml-enumerator provides some high-level interfaces for dealing with documents as a
   whole, but in our case, we're going to need to use the low-level Event interface to ensure
   minimal memory impact. So the function we're interested in is:</p>
  <codeblock id="x-12" outputclass="haskell">renderBuilder :: MonadIO m =&gt; RenderSettings -&gt; Enumeratee Event Builder m b</codeblock>
  <p id="x-13">In plain English, that means renderBytes takes some settings (we'll just use the defaults), and
   will then convert a stream of Events to a stream of Builders. This is looking pretty good, all we
   need now is a stream of Events.</p>
  <p id="x-14">Speaking of which, what should our XML document actually look like? It's pretty simple, we have
   a <codeph id="x-15">sphinx:docset</codeph> root element, a <codeph id="x-16">sphinx:schema</codeph> element
   containing a single <codeph id="x-17">sphinx:field</codeph> (which defines the content field), and then a
    <codeph id="x-18">sphinx:document</codeph> for each document in our database. That last element will have
   an id attribute and a child <codeph id="x-19">content</codeph> element.</p>
  <fig id="x-20">
   <title id="x-21">Sample xmlpipe document</title>
   <codeblock id="x-22" outputclass="xml">&lt;sphinx:docset xmlns:sphinx="http://sphinxsearch.com/"&gt;
    &lt;sphinx:schema&gt;
        &lt;sphinx:field name="content"/&gt;
    &lt;/sphinx:schema&gt;
    &lt;sphinx:document id="1"&gt;
        &lt;content&gt;bar&lt;/content&gt;
    &lt;/sphinx:document&gt;
    &lt;sphinx:document id="2"&gt;
        &lt;content&gt;foo bar baz&lt;/content&gt;
    &lt;/sphinx:document&gt;
&lt;/sphinx:docset&gt;</codeblock>
  </fig>
  <p id="x-23">Every document is going to start off with the same events (start the docset, start the schema,
   etc) and end with the same event (end the docset). So let's start off by defining those:</p>
  <codeblock id="x-24" outputclass="haskell">toName :: Text -&gt; X.Name
toName x = X.Name x (Just "http://sphinxsearch.com/") (Just "sphinx")

docset, schema, field, document, content :: X.Name
docset = toName "docset"
schema = toName "schema"
field = toName "field"
document = toName "document"
content = "content" -- no prefix

startEvents, endEvents :: [X.Event]
startEvents =
    [ X.EventBeginDocument
    , X.EventBeginElement docset []
    , X.EventBeginElement schema []
    , X.EventBeginElement field [("name", [X.ContentText "content"])]
    , X.EventEndElement field
    , X.EventEndElement schema
    ]

endEvents =
    [ X.EventEndElement docset
    ]</codeblock>
  <p id="x-25">So now that we have the shell of our document, we need to get the <codeph id="x-26">Event</codeph>s for each individual document. This is actually a fairly simple function:</p>
  <codeblock id="x-27" outputclass="haskell">pairToEvents :: (DocId, Doc) -&gt; [X.Event]
pairToEvents (docid, doc) =
    [ X.EventBeginElement document [("id", [X.ContentText $ toSinglePiece docid])]
    , X.EventBeginElement content []
    , X.EventContent $ X.ContentText $ unTextarea $ docContent doc
    , X.EventEndElement content
    , X.EventEndElement document
    ]</codeblock>
  <p id="x-28">We start the document element with an id attribute, start the content, insert the content, and
   then close both elements. We use toSinglePiece to convert a DocId into a Text value. Next, we
   need to be able to convert a stream of these pairs into a stream of events. For this, we can use
   the built-in concatMap function from Data.Enumerator.List: <codeph id="x-29">EL.concatMap
    pairToEvents</codeph>.</p>
  <p id="x-30">But what we <i id="x-31">really</i> want is to stream those events directly from the database. For most
   of this book, we've used the selectList function, but Persistent also provides the (more
   powerful) selectEnum function. So we end up with the function:</p>
  <codeblock id="x-32" outputclass="haskell">docEnum :: Enumerator X.Event (SqlPersist IO) a
docEnum = selectEnum [] [] $= EL.concatMap pairToEvents</codeblock>
  <p id="x-33">The $= operator joins together an enumerator and an enumeratee into a new enumerator. Now that
   we have our Event enumerator, all we need to do is surround it with the document start and end
   events. With concatEnums, this is a piece of cake:</p>
  <codeblock id="x-34" outputclass="haskell">fullDocEnum :: Enumerator X.Event (SqlPersist IO) a
fullDocEnum = concatEnums
    [ enumList 8 startEvents
    , docEnum
    , enumList 8 endEvents
    ]</codeblock>
  <p id="x-35">We're almost there, now we just need to tie it together in getXmlpipeR. The last trick is
   getting the monads to work correctly. Our fullDocEnum runs in the SqlPersist IO monad, since it
   needs to read from the database. But WAI needs something running in the IO monad, so we'll need
   to unwrap the SqlPersist. For that, we just need to use the runSqlPool function.</p>
  <p id="x-36">But it's just a little bit trickier than that. You see, our Enumerator is expecting to receive
   an Iteratee that lives in the SqlPersist IO monad, but the iteratee that WAI provides our
   application lives in the IO monad. So what we need to do is lift that inner monad. Fortunately,
   enumerator provides a function to do this for us: liftTrans. So our whole getXmlpipeR function
   is:</p>
  <codeblock id="x-37" outputclass="haskell">getXmlpipeR :: Handler RepXml
getXmlpipeR = do
    Searcher pool &lt;- getYesod
    sendWaiResponse $ ResponseEnumerator $ \sriter -&gt; do
        let iter = sriter status200 [("Content-Type", "text/xml")]
        flip runSqlPool pool $ run_
            $ fullDocEnum $$ renderBuilder def =$ liftTrans iter</codeblock>
  <p id="x-38">We get our connection pool from the foundation variable, then send a WAI response. The sriter
   value provided by WAI is of the (simplified) type <codeph id="x-39">Status -&gt; Headers -&gt; Iteratee</codeph>.
   We apply this function to a 200 status and a content-type header to get our actual iteratee. We
   then pipe together our enumerator (fullDocEnum)- which produces a stream of Events, an enumeratee
   (renderBuilder def) which converts a stream of Events to a stream of Builders, and our iteratee
   (liftTrans iter) which consumes that stream of Builders.</p>
  <p id="x-40">We're left with a value of type <codeph id="x-41">Iteratee Builder (SqlPersist IO) a</codeph>. We use
   run_ to turn this into a <codeph id="x-42">SqlPersist IO a</codeph>, and <codeph id="x-43">flip runSqlPool
    pool</codeph> to turn this into an <codeph id="x-44">IO a</codeph>. And at that point, we're done.</p>
 </conbody>
</concept>
